# DataAnalysis_DZ_Selenium
Этот проект - парсер с сайта https://www.hh.ru/. Код собирает информацию о вакансиях: ссылки, названия должности, зарплаты, необходимый опыт, название компании, город, станцию метро и сохраняет информацию в CSV-файл с названием "vacancies_python.csv". В качестве примера приведены вакансии с фильтром "Специалист по логистике".
# Структура проекта
DZ_Selenium.py: Основной файл для запуска парсера.
README.md: Описание и инструкция.
vacancies_python.csv: Файл, в который сохраняются результаты парсинга.
# Требования
Для запуска проекта вам понадобится Python версии 3.7 и выше, а также следующие библиотеки: beautifulsoup4, pandas, time, Selenium, webdriver
# Как использовать
1) Склонируйте репозиторий или скачайте исходный код.
2) Установите необходимые библиотеки
3( (*опционально) В файле DZ_Selenium.py можно изменить значение параметра url на нужный, а также количество страниц для парсинга (pages_to_fetch).
4) Запустите скрипт
5) После завершения работы программы откройте файл vacancies_python.csv, чтобы увидеть результаты.
# Настройка параметров
1) В параметре url указывается адрес страницы, с которой будет происходить парсинг, например: url="[https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&p={page}&region=1&room2=1](https://hh.ru/vacancies/specialist_po_logistike?page={page-1}&searchSessionId=e1e0606e-6e73-4eee-9e73-7f35fbc64c5d)"
2) Параметр pages_to_fetch задаёт число страниц, которые будут обработаны, например: pages_to_fetch = 15
# Структура CSV-файла
Файл vacancies_python.csv содержит следующие колонки:
1) Ссылка
2) Название должности
3) Зарплата (если она отсутствует, то указывается "Информация отсутствует")
4) Необходимый опыт (если она отсутствует, то указывается "Информация отсутствует")
5) Название компании (если она отсутствует, то указывается "Информация отсутствует")
6) Город (если она отсутствует, то указывается "Информация отсутствует")
7) Станция метро (если она отсутствует, то указывается "Информация отсутствует")
